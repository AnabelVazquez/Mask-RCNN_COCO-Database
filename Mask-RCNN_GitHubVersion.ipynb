{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04ed868",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 0. Import Dependences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6595468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2, cv2, random\n",
    "import os, json, itertools\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91076881",
   "metadata": {},
   "source": [
    "# 1. Create a function that change COCO Dataset (Input) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea7dcc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_dir = '/home/gus/SORCOM/Python2/DatasetTraining'\n",
    "\n",
    "def Get_EyeFundus_Data(image_dir):\n",
    "    json_file = os.path.join(image_dir, \"COCO_Dataset_IzqIzq.json\")\n",
    "    json_open = open(json_file)\n",
    "    imgs_anns = json.load(json_open)\n",
    "\n",
    "\n",
    "    images = imgs_anns[\"images\"]\n",
    "    annotations = imgs_anns[\"annotations\"]\n",
    "\n",
    "    n = 0\n",
    "    array = []\n",
    "\n",
    "    for i in annotations:\n",
    "        record = {}\n",
    "        array_anno = []\n",
    "        filename = img_dir + \"/\" + images[n]['file_name'].split(\"/\")[-1]\n",
    "        height = images[n]['height']\n",
    "        width = images[n]['width']\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        record_anno = {}\n",
    "        #print(n)\n",
    "        bbox = annotations[n]['bbox']\n",
    "        bbox_mode = BoxMode.XYXY_ABS\n",
    "        segmentation = annotations[n]['segmentation']\n",
    "        category_id = 0\n",
    "        iscrowd = 0\n",
    "        record_anno['bbox_mode'] = bbox_mode\n",
    "        record_anno['segmentation'] = segmentation\n",
    "     \n",
    "        max_x = 0\n",
    "        min_x = 9999999999\n",
    "        for i in range(len(segmentation[0])):\n",
    "            if i%2 == 0:\n",
    "                if segmentation[0][i]<min_x:\n",
    "                    min_x = segmentation[0][i]\n",
    "                if segmentation[0][i]>max_x:\n",
    "                    max_x = segmentation[0][i]\n",
    "                    \n",
    "        max_y = 0\n",
    "        min_y = 9999999999\n",
    "        for i in range(len(segmentation[0])):\n",
    "            if i%2 != 0:\n",
    "                if segmentation[0][i]<min_y:\n",
    "                    min_y = segmentation[0][i]\n",
    "                if segmentation[0][i]>max_y:\n",
    "                    max_y = segmentation[0][i]\n",
    "        \n",
    "        record_anno['bbox'] = [min_x,min_y,max_x,max_y]\n",
    "        record_anno['category_id'] = category_id\n",
    "        record_anno['iscrowd'] = iscrowd\n",
    "\n",
    "        array_anno.append(record_anno)\n",
    "        record[\"annotations\"] = array_anno\n",
    "        array.append(record)\n",
    "\n",
    "        n = n+1\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c5d065",
   "metadata": {},
   "source": [
    "# 2. Register EyeFundus Dataset (Training and Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ffc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [\"DatasetTraining\", \"DatasetTest\"]:\n",
    "    DatasetCatalog.register(d, lambda d=d: Get_EyeFundus_Data(d))\n",
    "    MetadataCatalog.get(d).set(thing_classes=[\"EyeFundus\"])\n",
    "eyefundus_metadata = MetadataCatalog.get('DatasetTraining')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46fb84",
   "metadata": {},
   "source": [
    "# 3. Visualize Dataset with the new format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79e79a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': 'DatasetIzqIzq/3video711.jpg', 'height': 1920, 'width': 1080, 'annotations': [{'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[350.0, 191.0, 300.0, 211.0, 248.0, 295.0, 214.0, 347.0, 210.0, 439.0, 252.0, 549.0, 290.0, 571.0, 350.0, 465.0, 398.0, 359.0, 420.0, 297.0]], 'bbox': [210.0, 191.0, 420.0, 571.0], 'category_id': 0, 'iscrowd': 0}]}\n",
      "{'file_name': 'DatasetIzqIzq/1video1038.jpg', 'height': 1920, 'width': 1080, 'annotations': [{'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[380.0, 413.0, 324.0, 447.0, 278.0, 539.0, 248.0, 615.0, 252.0, 695.0, 264.0, 771.0, 318.0, 847.0, 384.0, 803.0, 438.0, 753.0, 450.0, 705.0, 442.0, 681.0, 412.0, 665.0, 412.0, 633.0, 420.0, 617.0, 418.0, 591.0, 406.0, 525.0, 398.0, 481.0, 396.0, 445.0]], 'bbox': [248.0, 413.0, 450.0, 847.0], 'category_id': 0, 'iscrowd': 0}]}\n",
      "{'file_name': 'DatasetIzqIzq/1video432.jpg', 'height': 1920, 'width': 1080, 'annotations': [{'bbox_mode': <BoxMode.XYXY_ABS: 0>, 'segmentation': [[414.0, 667.0, 378.0, 709.0, 354.0, 773.0, 348.0, 857.0, 366.0, 949.0, 412.0, 1003.0, 494.0, 951.0, 548.0, 871.0, 552.0, 781.0, 540.0, 695.0, 486.0, 649.0, 440.0, 667.0]], 'bbox': [348.0, 649.0, 552.0, 1003.0], 'category_id': 0, 'iscrowd': 0}]}\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = Get_EyeFundus_Data(\"DatasetTraining\")\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    print(d)\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=eyefundus_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imshow('visgetimage', vis.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5cee08",
   "metadata": {},
   "source": [
    "# 4. Set the training Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ef78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = ('DatasetTraining',)\n",
    "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough, but you can certainly train longer\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (EyeFundus)\n",
    "cfg.OUTPUT_DIR = \"output\"\n",
    "#cfg.MODEL.DEVICE = \"cpu\" #In case your computer doest have GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eba615d",
   "metadata": {},
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ac3993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/21 15:37:11 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/21 15:37:11 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 307 images left.\n",
      "\u001b[32m[12/21 15:37:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/21 15:37:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/21 15:37:11 d2.data.common]: \u001b[0mSerializing 307 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/21 15:37:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.15 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/21 15:37:11 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/21 15:37:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[12/21 15:37:15 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 19  total_loss: 1.811  loss_cls: 0.7457  loss_box_reg: 0.3166  loss_mask: 0.6946  loss_rpn_cls: 0.03199  loss_rpn_loc: 0.008668  time: 0.2228  data_time: 0.0125  lr: 1.6068e-05  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:20 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 39  total_loss: 1.631  loss_cls: 0.4967  loss_box_reg: 0.3808  loss_mask: 0.6805  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.00562  time: 0.2192  data_time: 0.0026  lr: 3.2718e-05  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:24 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 59  total_loss: 1.458  loss_cls: 0.3292  loss_box_reg: 0.4443  loss_mask: 0.6474  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.005923  time: 0.2189  data_time: 0.0028  lr: 4.9367e-05  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:29 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 79  total_loss: 1.298  loss_cls: 0.2733  loss_box_reg: 0.4231  loss_mask: 0.5951  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.004958  time: 0.2196  data_time: 0.0027  lr: 6.6017e-05  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:33 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 99  total_loss: 1.273  loss_cls: 0.2557  loss_box_reg: 0.4543  loss_mask: 0.5487  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.005283  time: 0.2198  data_time: 0.0027  lr: 8.2668e-05  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:37 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 119  total_loss: 1.244  loss_cls: 0.2339  loss_box_reg: 0.5017  loss_mask: 0.4722  loss_rpn_cls: 0.005376  loss_rpn_loc: 0.003516  time: 0.2192  data_time: 0.0027  lr: 9.9318e-05  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:42 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 139  total_loss: 1.096  loss_cls: 0.1877  loss_box_reg: 0.5164  loss_mask: 0.3853  loss_rpn_cls: 0.003757  loss_rpn_loc: 0.003937  time: 0.2194  data_time: 0.0026  lr: 0.00011597  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:47 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 159  total_loss: 1.045  loss_cls: 0.1499  loss_box_reg: 0.5349  loss_mask: 0.3422  loss_rpn_cls: 0.00353  loss_rpn_loc: 0.003999  time: 0.2219  data_time: 0.0026  lr: 0.00013262  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:51 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 179  total_loss: 0.881  loss_cls: 0.1006  loss_box_reg: 0.5043  loss_mask: 0.2795  loss_rpn_cls: 0.0008903  loss_rpn_loc: 0.004675  time: 0.2229  data_time: 0.0027  lr: 0.00014927  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:37:56 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 199  total_loss: 0.7126  loss_cls: 0.06944  loss_box_reg: 0.4017  loss_mask: 0.216  loss_rpn_cls: 0.000419  loss_rpn_loc: 0.004031  time: 0.2230  data_time: 0.0026  lr: 0.00016592  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:38:00 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 219  total_loss: 0.6079  loss_cls: 0.04935  loss_box_reg: 0.3113  loss_mask: 0.2212  loss_rpn_cls: 0.003573  loss_rpn_loc: 0.00435  time: 0.2234  data_time: 0.0028  lr: 0.00018257  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:38:05 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 239  total_loss: 0.529  loss_cls: 0.05236  loss_box_reg: 0.2554  loss_mask: 0.2231  loss_rpn_cls: 5.754e-05  loss_rpn_loc: 0.003813  time: 0.2235  data_time: 0.0027  lr: 0.00019922  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:38:09 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 259  total_loss: 0.5456  loss_cls: 0.04837  loss_box_reg: 0.2375  loss_mask: 0.2249  loss_rpn_cls: 0.001396  loss_rpn_loc: 0.003366  time: 0.2238  data_time: 0.0026  lr: 0.00021587  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:38:14 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 279  total_loss: 0.503  loss_cls: 0.04951  loss_box_reg: 0.245  loss_mask: 0.2093  loss_rpn_cls: 0.0001968  loss_rpn_loc: 0.003145  time: 0.2238  data_time: 0.0028  lr: 0.00023252  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:38:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.5196  loss_cls: 0.05232  loss_box_reg: 0.2459  loss_mask: 0.2075  loss_rpn_cls: 0.0002156  loss_rpn_loc: 0.002105  time: 0.2240  data_time: 0.0027  lr: 0.00024917  max_mem: 2672M\n",
      "\u001b[32m[12/21 15:38:19 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:01:06 (0.2240 s / it)\n",
      "\u001b[32m[12/21 15:38:19 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:07 (0:00:00 on hooks)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume = False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a995ec",
   "metadata": {},
   "source": [
    "# 6. Save model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827518cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = ('DatasetTest', )\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca578fa0",
   "metadata": {},
   "source": [
    "# 7. Inference on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f76ae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': Instances(num_instances=1, image_height=1920, image_width=1080, fields=[pred_boxes: Boxes(tensor([[ 339.1504,  646.5409,  563.3959, 1079.3363]], device='cuda:0')), scores: tensor([0.9844], device='cuda:0'), pred_classes: tensor([0], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]], device='cuda:0')])}\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "dataset_dicts = Get_EyeFundus_Data(\"DatasetTraining\")\n",
    "for d in random.sample(dataset_dicts, 10):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    print(outputs)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=MetadataCatalog.get(\"balloon_val\"), \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imshow('final', v.get_image()[:, :, ::-1])\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f7470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
